# import standard modules
import logging
import sys
import json
import os
import argparse
import time
from dataclasses import dataclass, asdict
import threading
import requests
from google.cloud import pubsub_v1
from google.api_core.exceptions import DeadlineExceeded


# import 3rd party modules

# import local modules
from gcp_utils.settings import (
    GOOGLE_CLOUD_PROJECT,
    GOOGLE_COMPUTE_REGION,
    GOOGLE_PUBSUB_TOPIC,
    logger
)
from gcp_utils import pubsub
import cloud_processor

# set the logging level to always be DEBUG in this module
logger.setLevel(logging.DEBUG)

#TODO: test preemptive logic
#TODO: look at article about extend ACK time: https://cloud.google.com/pubsub/docs/lease-management?&_ga=2.61453679.-237567142.1575920178#lease_management_configuration
#TODO: Reduce the ACK timeout on the subscription so it will be reassigned to another server.

def run_prediction_server():
    """
        Loop pulling messages until interrupted.
    """

    # Define your data and attributes.  These are optional and only used for filtering messages.
    attributes = {}
    sub_topic_id = GOOGLE_PUBSUB_TOPIC 
    pub_topic_id = GOOGLE_PUBSUB_TOPIC 

    subscriber = pubsub_v1.SubscriberClient(credentials=gcp.credentials())

    logger.info(f"Creating a subscription for topic: {sub_topic_id}")
    subscription_path = subscription(topic_id=topic_id, subscription_id="prediction_server", project_id=project_id, **attributes)
    logger.debug(f'Created a subscription path: {subscription_path}')
 
    try:
        # Event meant to hold the state as to whether need to stop processing.
        stop_event = threading.Event()
        keep_alive_thread = None

        # loop until receiving a signal to exit.
        while True:
            # Pull a message from PubSub queue
            logging.debug(f"Pull messages: on {pub_topic_id} using subscription {subscription_id}")

            try:
                response = subscriber.pull(
                    request={
                        "subscription": subscription_path,
                        "max_messages": 1,   # pull 1 message at a time
                    },
                    timeout=60,  # wait for this amount of seconds for a message.
                )
            except DeadlineExceeded:
                response = None

            # Serially process (i.e., one at a time) all the messages received, there will be no messages if it times out.
            # If the max_messages = 1, then there will only be one message, but looping just in case max_messages isn't 1 above.
            received = []
            if response and response.received_messages:
                for received_message in response.received_messages:
                    logging.debug(f"[pubsub] PULL: %s (%s)", 
                        repr(received_message.message.data),
                        repr(received_message.message.attributes))
 
                    # Start a thread to keep extending the message's ack deadline to PubSub so it will not redistribute message to another server.
                    ack_extension_period = 30  # it will extend the ACK deadline every X seconds

                    keep_alive_thread = threading.Thread(
                        target=extend_ack_deadline, 
                        args=(received_message, ack_extension_period, stop_event)
                    )

                    # Start the thread, this will run in parallel as the message is being processed
                    keep_alive_thread.start()

                    # convert message.text to a dataclass
                    data = cloud_processor.input_message(**json.loads(message.text))

                    # process the message
                    cloud_processor.process_message(data)

                    # ack the message, only ack the message if successfully processed.
                    logging.info(f'Acking message: {receivedmessage.message_id}, message.ack_id: {receivedmessage.ack_id}')
                    received_message.ack()
                
                    # Set the stop event so the keep-alive thread will stop
                    stop_event.set()  # a small race condition exists.  If a sigint is received after the ack but before this, it may cause problems.

                    # Wait for the thread to finish
                    keep_alive_thread.join()
 

    except KeyboardInterrupt:
        logger.info(f'keyboard interrupt received...exiting')
        check_preemption()
    except Exception as e:
        logger.exception(e)
    finally:
        # Signal the keep-alive thread to stop and wait for it to finish
        # This should cause a timeout on any retrieved messages that were not ack'd due to being interrupted.
        stop_event.set()
        if keep_alive_thread is not None:
            logging.debug(f"Joining keep-alive thread")       
            keep_alive_thread.join()

def extend_ack_deadline(message, ack_extension_period, stop_event):
    """
    Periodically extends the ack deadline of a message until stop_event is set.
    
    ack_extension_period should be relatively short so this thread will finish 
    """
    ack_period = ack_extension_period / 2

    while not stop_event.is_set():
        message.modify_ack_deadline(ack_extension_period)
        logging.debug(f"Extended ACK deadline for message: {message.message_id} to {ack_period} seconds.")
        time.sleep(ack_period)

def check_preemption():
    """
    Checks the instance's metadata for a preemption notice.  This isn't required but will help log with GCE pre-empts this server.
    """
    METADATA_URL = "http://metadata.google.internal/computeMetadata/v1/instance/preempted"
    HEADERS = {"Metadata-Flavor": "Google"}

    try:
        response = requests.get(METADATA_URL, headers=HEADERS)
        if response.text == "TRUE":
            logging.info("Preemption notice received. Preparing to shutdown.")
    except requests.RequestException as e:
        logging.error(f"Error checking preemption status: {e}")


# main function
if __name__ == "__main__":

    logging.info(f"Starting prediction server")
    run_prediction_server()

    # exit the program
    sys.exit(0)






    

